# Triage Planner Framework

We are building **two complementary components** that work together to help EMT crews and hospital
staff triage patients faster:

1. **LLM Summarizer** â€“ ingests narrative reports (for example the EMT notes listed in
   [PREP-5004 examples](https://www.vdh.virginia.gov/content/uploads/sites/23/2016/05/PREP-5004Examples.pdf))
   plus structured vitals (age, blood type, etc.) and turns them into a consistent JSON summary.
2. **Decision Tree Prioritizer** â€“ consumes the JSON summaries and produces a priority score or
   label that indicates who should be treated first.

> ğŸ’¡ **Goal for this commit:** provide a _beginner-friendly scaffold_ with very explicit comments and
> TODO markers so new teammates can fill in the important pieces themselves.

## Repository layout

```
.
â”œâ”€â”€ config/
â”‚   â””â”€â”€ training.example.yaml   # Annotated template for LLM training hyper-parameters
â”œâ”€â”€ dataset/                    # Raw clinical JSON dumps (needs review/cleanup by the team)
â”œâ”€â”€ samples/patients.sample.json# Mini file to test the pipeline manually
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ clinical_summary/       # LLM summarizer package (heavily commented scaffold)
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ data.py
â”‚   â”‚   â”œâ”€â”€ prompts.py
â”‚   â”‚   â”œâ”€â”€ training.py
â”‚   â”‚   â””â”€â”€ inference.py
â”‚   â””â”€â”€ triage_planner/
â”‚       â””â”€â”€ decision_tree.py    # Placeholder for the rule-based/decision-tree prioritizer
â””â”€â”€ README.md                   # This guide (plan, task breakdown, onboarding steps)
```

Person A: Ehan Shah /n
Person B: Raaghava Deepak /n
Person C: David Castellanos /n
Person D: Dhruv Palli /n

## Beginner-friendly onboarding plan

The work is intentionally split so at least two people can collaborate without stepping on each
other. Each task references the module(s) involved and notes what is already prepared versus what
still needs to be coded.

| Workstream | Sub-task | Owner suggestion | Status | Notes |
|------------|----------|------------------|--------|-------|
| **LLM Summarizer** | Review/clean the raw `dataset/*.json` files | Person A | â¬œï¸ TODO | Make sure every file is a valid JSON array and redact PHI if necessary. |
| | Implement prompt+target builders inside `src/clinical_summary/prompts.py` | Person A | â¬œï¸ TODO | Skeleton + docstrings exist; fill in `_summarize_condition_text` with real logic. |
| | Finish `load_patient_records` + `build_hf_dataset` in `data.py` | Person B | â¬œï¸ TODO | Current file explains each step and where to insert code. |
| | Complete the training CLI in `training.py` | Person B | â¬œï¸ TODO | Use Hugging Face `Trainer`; the comments outline the flow. |
| | Complete inference CLI in `inference.py` | Person B | â¬œï¸ TODO | Should mirror training tokenizer/model loading. |
| | Experiment tracking + evaluation metrics | Person C | â¬œï¸ TODO | See TODO in `training.py` for hooking custom metrics. |
| **Decision Tree Prioritizer** | Define triage criteria with clinical lead | Person D | â¬œï¸ TODO | E.g., unstable vitals > allergies > transport time. Document in README once finalized. |
| | Implement priority scoring in `triage_planner/decision_tree.py` | Person D | â¬œï¸ TODO | Function `assign_priority` currently returns `NotImplementedError`. |
| | Connect LLM output JSON to the decision tree | Person A + D | â¬œï¸ TODO | Determine shared schema (see `samples/patients.sample.json`). |
| **Project Ops** | Document experiments + share checkpoints | Rotating | â¬œï¸ TODO | Use `/artifacts` folder (not tracked) per config template. |

## How everything fits together

```
Narrative report + vitals
          â”‚
          â–¼
  clinical_summary.prompts  (format instruction + desired JSON fields)
          â”‚
          â–¼
  clinical_summary.data     (convert dataset to Hugging Face DatasetDict)
          â”‚
          â–¼
  clinical_summary.training (fine-tune FLAN-T5 or any free seq2seq model)
          â”‚
          â–¼
  clinical_summary.inference (produce JSON summaries for new patients)
          â”‚
          â–¼
triage_planner.decision_tree (score priority / produce flowchart result)
```

## Environment setup

```bash
python -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt  # transformers, datasets, etc.
export PYTHONPATH=src  # so "python -m clinical_summary.training" works
```

The Python dependencies are already listed, but installation may fail in restricted environments.
If that happens, try running on a local machine or Colab where Hugging Face downloads are allowed.

## Implementation roadmap (high level)

1. **Data audit (week 1):** confirm file formats, remove corrupted rows, and list mandatory fields
   (age, blood type, blood pressure, mental status, etc.). Update `samples/patients.sample.json`
   when you find additional attributes so the inference example stays realistic.
2. **Prompt/target iteration (week 1â€“2):** experiment with how the prompt is phrased and which
   fields we expect in the JSON output. Keep instructions short for small models (FLAN-T5) and add
   more detail for larger models (Llama 3, Mixtral, etc.).
3. **Fine-tuning loop (week 2):** finish `training.py`, run a dry-run (`--dry-run` only loads data),
   then execute a full training job when GPU time is available. Save checkpoints under
   `artifacts/<run-name>` (folder is ignored by git so add a README there for context).
4. **Decision tree prototype (week 2):** codify your triage flowchart in `decision_tree.py`. Start
   simple (e.g., unstable vitals = priority 1) and refine as you gather real EMT feedback.
5. **Integration test (week 3):** feed LLM-generated JSON into the decision tree and compare the
   automated priority order against clinician expectations. Adjust either component as needed.

## Helpful tips embedded in the code

- Every Python file inside `src/` now contains **big block comments** that explain _why_ a function
  exists and mark exactly where to add logic. Search for `TODO(team)` to find your assignments.
- If you are new to Hugging Face, read the inline comments in `training.py` before touching the code.
  They walk you through tokenizer loading, dataset mapping, and the trainer loop.
- The decision tree file gives a plain-English recipe for how to transform vitals (SBP/DBP, heart
  rate, Glasgow Coma Score, etc.) into a simple score. You can start with `if/elif` statements or
  use `sklearn.tree.DecisionTreeClassifier` later.

## Next steps checklist

- [ ] Confirm raw data sources (Virginia EMT narratives + Physionet MIETIC) are downloaded into
      `dataset/`.
- [ ] Decide on the **minimum viable JSON schema** (fields and types) for the LLM output.
- [ ] Finish the `TODO` blocks in `src/clinical_summary/*.py` and `src/triage_planner/decision_tree.py`.
- [ ] Run the dry-run command to ensure data loading works before launching expensive training jobs.
- [ ] Pair the LLM predictions with the decision tree scoring logic to produce a ranked patient list.

Once these boxes are checked we can worry about evaluation metrics, model deployment, and UI/UX.













System Architecture:
EMS Narrative Report (Text)
         â†“
    Preprocessing (Clean text, remove PHI)
         â†“
    LLM Extraction (Extract structured JSON)
         â†“
    Decision Tree (Predict priority 1-5)
         â†“
    Triage Priority Assignment
ğŸ¥ Triage Priority Levels

Immediate - Life-threatening, needs immediate intervention
Emergent - Serious but stable, needs prompt care
Urgent - Stable but needs medical care
Less Urgent - Minor injury, can wait
Non-Urgent - Can wait extended period

ğŸš€ Quick Start
Installation
bash# Clone repository
git clone https://github.com/ehanrsha/llmproject.git
cd llmproject

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
Basic Usage
bash# Run inference on a single narrative
python scripts/run_inference.py --input data/raw/narrative.txt

# Process all narratives in a directory
python scripts/run_inference.py --input-dir data/raw/narratives/

# Quick test with text
python scripts/run_inference.py --text "45 y/o male with chest pain, BP 160/95, HR 110..."
Run Tests
bash# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_pipeline.py -v

# Run with coverage
pytest --cov=src tests/
ğŸ“ Project Structure
llmproject/
â”œâ”€â”€ config/                          # Configuration files
â”‚   â”œâ”€â”€ training.example.yaml        # Training configuration
â”‚   â”œâ”€â”€ llm_config.yaml             # LLM model settings
â”‚   â”œâ”€â”€ data_config.yaml            # Data paths and preprocessing
â”‚   â””â”€â”€ decision_tree_config.yaml   # Decision tree settings
â”‚
â”œâ”€â”€ data/                           # Data at various stages
â”‚   â”œâ”€â”€ raw/                        # Original narrative reports
â”‚   â”œâ”€â”€ processed/                  # Cleaned narratives
â”‚   â”œâ”€â”€ json_outputs/               # LLM-generated JSON
â”‚   â””â”€â”€ splits/                     # Train/val/test splits
â”‚
â”œâ”€â”€ models/                         # Trained models
â”‚   â”œâ”€â”€ checkpoints/                # LLM model weights
â”‚   â””â”€â”€ decision_tree/              # Decision tree models
â”‚
â”œâ”€â”€ src/                           # Source code
â”‚   â”œâ”€â”€ data/                      # Data handling
â”‚   â”‚   â”œâ”€â”€ data_loader.py         # Load MIMIC-III and other datasets
â”‚   â”‚   â”œâ”€â”€ preprocessor.py        # Clean and normalize text
â”‚   â”‚   â””â”€â”€ json_schema.py         # Define JSON extraction structure
â”‚   â”‚
â”‚   â”œâ”€â”€ clinical_summary/          # LLM component
â”‚   â”‚   â”œâ”€â”€ config.py              # LLM configuration
â”‚   â”‚   â”œâ”€â”€ data.py                # LLM data preparation
â”‚   â”‚   â”œâ”€â”€ inference.py           # Run LLM extraction
â”‚   â”‚   â”œâ”€â”€ prompts.py             # Prompt templates
â”‚   â”‚   â””â”€â”€ training.py            # LLM training
â”‚   â”‚
â”‚   â”œâ”€â”€ triage_planner/            # Decision tree component
â”‚   â”‚   â””â”€â”€ decision_tree.py       # Decision tree logic
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                     # Utilities
â”‚   â”‚   â”œâ”€â”€ logging.py             # Logging setup
â”‚   â”‚   â””â”€â”€ metrics.py             # Evaluation metrics
â”‚   â”‚
â”‚   â””â”€â”€ pipeline/                  # End-to-end orchestration
â”‚       â””â”€â”€ end_to_end.py          # Connect LLM + decision tree
â”‚
â”œâ”€â”€ scripts/                       # Executable scripts
â”‚   â”œâ”€â”€ train_llm.py              # Train LLM (TODO)
â”‚   â”œâ”€â”€ train_tree.py             # Train decision tree (TODO)
â”‚   â””â”€â”€ run_inference.py          # Run inference on narratives
â”‚
â”œâ”€â”€ tests/                        # Unit tests
â”‚   â””â”€â”€ test_pipeline.py          # Test end-to-end pipeline
â”‚
â”œâ”€â”€ notebooks/                    # Jupyter notebooks (optional)
â”œâ”€â”€ docs/                         # Documentation
â”œâ”€â”€ samples/                      # Sample data
â”‚   â””â”€â”€ patients.sample.json     # Example JSON structure
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ pyproject.toml
ğŸ”§ Components
1. Data Processing (src/data/)
Data Loader (data_loader.py)

Loads narrative reports from MIMIC-III dataset
Supports text files, JSON/JSONL formats
Creates train/validation/test splits

Preprocessor (preprocessor.py)

Cleans narrative text
Removes Protected Health Information (PHI)
Normalizes whitespace and formatting
Filters by length

JSON Schema (json_schema.py)

Defines structured output format for LLM
Patient info, vitals, symptoms, medical history
Validation and serialization utilities

2. LLM Component (src/clinical_summary/)
Extracts structured information from narrative text:

Patient demographics (age, sex, weight)
Vital signs (BP, HR, RR, SpO2, temp)
Symptoms and complaints
Medical history
Incident details
Severity indicators

3. Decision Tree Component (src/triage_planner/)
Uses extracted JSON to predict triage priority:

Takes features from JSON (vitals, symptoms, severity flags)
Applies decision tree classification
Returns priority level (1-5)

4. Pipeline (src/pipeline/)
Orchestrates the complete workflow:

Text preprocessing
LLM extraction
Feature engineering
Priority prediction
Result formatting

5. Utilities (src/utils/)
Logging (logging.py)

Setup logging for training and inference
Track metrics and progress

Metrics (metrics.py)

Accuracy, precision, recall, F1 score
Confusion matrix
Critical error rate
Weighted accuracy
LLM extraction accuracy

ğŸ“Š Data Sources
MIMIC-III Dataset

Clinical notes from ICU admissions
Used for training LLM and decision tree
Access: https://physionet.org/content/mimiciii/

EMS Narrative Examples

Sample reports: https://www.vdh.virginia.gov/content/uploads/sites/23/2016/05/PREP-5004Examples.pdf
